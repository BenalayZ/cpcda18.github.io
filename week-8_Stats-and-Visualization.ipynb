{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australian_Broadcasting_Commission_2006.zip  Inaugural_Speeches.zip\r\n",
      "George_Eliot.zip\t\t\t     Jane_Austen.zip\r\n",
      "Herman_Melville.zip\t\t\t     Joseph_Conrad.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls week/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the packages we will use below.\n",
    "\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download zipped texts from GitHub, then unzip the directories.\n",
    "\n",
    "os.chdir('/sharedfolder/')\n",
    "\n",
    "!wget -N https://github.com/pcda17/pcda17.github.io/blob/master/week/5/Emerson.zip?raw=true -O Emerson.zip\n",
    "!unzip -o Emerson.zip\n",
    "\n",
    "!wget -N https://github.com/pcda17/pcda17.github.io/blob/master/week/5/Wilde.zip?raw=true -O Wilde.zip\n",
    "!unzip -o Wilde.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, load each author’s works as a list of strings.\n",
    "\n",
    "corpus_1_dir = \"/sharedfolder/Emerson/\"\n",
    "corpus_2_dir = \"/sharedfolder/Wilde/\"\n",
    "\n",
    "##\n",
    "\n",
    "os.chdir(corpus_1_dir)\n",
    "\n",
    "corpus_1_filenames = os.listdir(\"./\")\n",
    "\n",
    "corpus_1_texts = []\n",
    "\n",
    "for filename in corpus_1_filenames:\n",
    "    text = open(filename).read().replace(\"\\n\",\" \") #replaces newline characters with spaces\n",
    "    corpus_1_texts.append(text)\n",
    "\n",
    "##\n",
    "    \n",
    "os.chdir(corpus_2_dir)\n",
    "\n",
    "wilde_filenames = os.listdir(\"./\")\n",
    "\n",
    "wilde_texts = []\n",
    "\n",
    "for filename in wilde_filenames:\n",
    "    text = open(filename).read().replace(\"\\n\",\" \") #replaces newline characters with spaces\n",
    "    wilde_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_1_blobs = [TextBlob(item) for item in corpus_1_texts]\n",
    "wilde_blobs = [TextBlob(item) for item in wilde_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall that 'blob.words' is a list of words.\n",
    "\n",
    "blob = random.choice(corpus_1_blobs)\n",
    "\n",
    "blob.words[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANd 'blob.sentences' is a list of Sentence objects.\n",
    "\n",
    "blob = random.choice(corpus_1_blobs)\n",
    "\n",
    "blob.sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ▷ Simple sentiment analysis with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative polarity example\n",
    "from textblob import TextBlob\n",
    "\n",
    "text=\"This is a very mean and nasty sentence.\"\n",
    "\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# result between -1 and +1\n",
    "sentiment_score=blob.sentiment.polarity  # <--\n",
    "\n",
    "print(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive polarity example\n",
    "\n",
    "text=\"This is a nice and positive sentence.\"\n",
    "\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# result between -1 and +1\n",
    "sentiment_score=blob.sentiment.polarity  # <--\n",
    "\n",
    "print(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High subjectivity example\n",
    "\n",
    "text=\"This is a very mean and nasty sentence.\"\n",
    "\n",
    "blob = TextBlob(sanitize(text))\n",
    "\n",
    "# result between 0 and +1\n",
    "sentiment_score=blob.sentiment.subjectivity  # <--\n",
    "\n",
    "print sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low subjectivity example\n",
    "\n",
    "text=\"This sentence states a fact.\"\n",
    "\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# result between -1 and +1\n",
    "sentiment_score=blob.sentiment.subjectivity  # <--\n",
    "\n",
    "print(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ▷ Plotting Sentiment Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's map sentiment ratings across the course of a full book.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Viewing available plot styles and selecting one to use.\n",
    "\n",
    "pprint(plt.style.available)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new Emerson TextBlob object\n",
    "\n",
    "emerson_blob = random.choice(corpus_1_blobs)\n",
    "\n",
    "random_emerson_sentence = random.choice(emerson_blob.sentences)\n",
    "\n",
    "print(random_emerson_sentence)\n",
    "print()\n",
    "print(random_emerson_sentence.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emerson_sentiments=[item.sentiment.polarity for item in emerson_blob.sentences]\n",
    "\n",
    "emerson_sentiments[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(emerson_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing our data before plotting\n",
    "\n",
    "emerson_sentiments_pd = pd.Series(emerson_sentiments)\n",
    "emerson_sentiments_smooth = emerson_sentiments_pd.rolling(window=100).mean()\n",
    "\n",
    "print(emerson_sentiments_smooth[195:210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(emerson_sentiments_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentiment = max(emerson_sentiments_smooth[199:])\n",
    "\n",
    "print(max_sentiment) # max sentiment polarity value\n",
    "\n",
    "max_sent_index = list(emerson_sentiments_smooth).index(max_sentiment) # index position of the 'max_sentiment' value\n",
    "\n",
    "print(emerson_blob.sentences[max_sent_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sentiment=min(emerson_sentiments_smooth[199:])\n",
    "\n",
    "print(min_sentiment) # min sentiment polarity value\n",
    "\n",
    "min_sent_index=list(emerson_sentiments_smooth).index(min_sentiment) # index position of the 'min_sentiment' value\n",
    "\n",
    "print(emerson_blob.sentences[min_sent_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austen_sentiments=[sentence.sentiment.polarity for sentence in austen_blob.sentences]\n",
    "#print austen_sentiments[:10]\n",
    "austen_sentiments_pd=pd.Series(austen_sentiments)\n",
    "austen_sentiments_smooth=austen_sentiments_pd.rolling(window=200).mean()\n",
    "#print austen_sentiments_smooth[190:210]\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(austen_sentiments_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentiment=max(austen_sentiments_smooth[199:])\n",
    "print max_sentiment # max sentiment polarity value\n",
    "\n",
    "max_sent_index=list(austen_sentiments_smooth).index(max_sentiment) # index position of the 'max_sentiment' value\n",
    "print austen_blob.sentences[max_sent_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sentiment=min(austen_sentiments_smooth[199:])\n",
    "print min_sentiment # min sentiment polarity value\n",
    "\n",
    "min_sent_index=list(austen_sentiments_smooth).index(min_sentiment) # index position of the 'min_sentiment' value\n",
    "print austen_blob.sentences[min_sent_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating functions to expedite the steps we put together above process\n",
    "# These accept an optional second argument for smoothing level. Default is 200 windows.\n",
    "\n",
    "def plot_polarity(text_in,window=200):\n",
    "    blob = TextBlob(text_in)\n",
    "    sentiments=[sentence.sentiment.polarity for sentence in blob.sentences]\n",
    "    sentiments_pd=pd.Series(sentiments)\n",
    "    sentiments_smooth=sentiments_pd.rolling(window).mean()\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.plot(sentiments_smooth)\n",
    "\n",
    "def plot_subjectivity(text_in,window=200):\n",
    "    blob = TextBlob(text_in)\n",
    "    sentiments=[sentence.sentiment.subjectivity for sentence in blob.sentences]\n",
    "    sentiments_pd=pd.Series(sentiments)\n",
    "    sentiments_smooth=sentiments_pd.rolling(window).mean()\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.plot(sentiments_smooth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persuasion Subjectivity\n",
    "\n",
    "import urllib2\n",
    "url=\"http://principalhand.org/workshop-data/Austen_Persuasion.txt\"\n",
    "temp_string=urllib2.urlopen(url).read()\n",
    "temp_string=temp_string.replace(\"\\r\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \")\n",
    "\n",
    "\n",
    "#plot_polarity(temp_string)\n",
    "plot_subjectivity(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subjectivity(temp_string,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pride and Prejudice Subjectivity\n",
    "\n",
    "import urllib2\n",
    "url=\"http://www.gutenberg.org/cache/epub/1342/pg1342.txt\"\n",
    "temp_string=urllib2.urlopen(url).read()\n",
    "temp_string=temp_string.replace(\"\\r\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \")\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "#plot_polarity(temp_string)\n",
    "plot_subjectivity(temp_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emma Subjectivity\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url=\"https://www.gutenberg.org/files/158/158-0.txt\"\n",
    "temp_string = urlopen(url).read().decode('utf8')\n",
    "temp_string=temp_string.replace(\"\\r\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \")\n",
    "\n",
    "\n",
    "#plot_polarity(temp_string)\n",
    "plot_subjectivity(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sense and Sensibility Subjectivity\n",
    "\n",
    "import urllib2\n",
    "url=\"http://www.gutenberg.org/cache/epub/161/pg161.txt\"\n",
    "temp_string=urllib2.urlopen(url).read()\n",
    "temp_string=temp_string.replace(\"\\r\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \")\n",
    "\n",
    "\n",
    "#plot_polarity(temp_string)\n",
    "plot_subjectivity(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjectivity: New York Times Current History; The European War, Vol 2, No. 3, June, 1915\n",
    "\n",
    "import urllib2\n",
    "url=\"http://www.gutenberg.org/cache/epub/15480/pg15480.txt\"\n",
    "temp_string=urllib2.urlopen(url).read()\n",
    "temp_string=temp_string.replace(\"\\r\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \")\n",
    "\n",
    "#plot_polarity(temp_string)\n",
    "plot_subjectivity(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huckleberry Finn Polarity\n",
    "\n",
    "import urllib2\n",
    "url=\"https://www.gutenberg.org/files/76/76-0.txt\"\n",
    "temp_string=urllib2.urlopen(url).read()\n",
    "temp_string=temp_string.replace(\"\\r\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \")\n",
    "\n",
    "\n",
    "plot_polarity(temp_string)\n",
    "#plot_subjectivity(temp_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ▷ Plotting smoothed random data (for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting completely random data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_vals=np.random.rand(4000)\n",
    "\n",
    "vals_pd=pd.Series(random_vals)\n",
    "vals_smooth=vals_pd.rolling(window=200).mean()\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(vals_smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ▷ Sentiment Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_polarity(text_in):\n",
    "    blob = TextBlob(text_in)\n",
    "    sentiments=[sentence.sentiment.polarity for sentence in blob.sentences]\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.hist(sentiments_smooth)\n",
    "\n",
    "def hist_subjectivity(text_in):\n",
    "    blob = TextBlob(text_in)\n",
    "    sentiments=[sentence.sentiment.subjectivity for sentence in blob.sentences]\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.hist(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import urllib2\n",
    "#url=\"http://principalhand.org/workshop-data/Austen_Persuasion.txt\"\n",
    "#temp_string=urllib2.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_string = corpus_1_texts[4]\n",
    "\n",
    "hist_subjectivity(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions remove zero values before plotting.\n",
    "\n",
    "def hist_polarity_filtered(text_in):\n",
    "    blob = TextBlob(text_in.decode(\"utf8\"))\n",
    "    sentiments=[sentence.sentiment.polarity for sentence in blob.sentences]\n",
    "    sentiments=[x for x in sentiments if x != 0]\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.hist(sentiments)\n",
    "\n",
    "def hist_subjectivity_filtered(text_in):\n",
    "    blob = TextBlob(text_in.decode(\"utf8\"))\n",
    "    sentiments=[sentence.sentiment.subjectivity for sentence in blob.sentences]\n",
    "    sentiments=[x for x in sentiments if x != 0]\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.hist(sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_polarity_filtered(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "url=\"http://principalhand.org/workshop-data/Melville_Moby-Dick.txt\"\n",
    "melville_string=urllib2.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_polarity_filtered(melville_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ▷ Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(' '.join(corpus_1_texts))\n",
    "melville_sentiments=[sentence.sentiment.subjectivity for sentence in blob.sentences]\n",
    "np.mean(melville_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(' '.join(corpus_2_texts))\n",
    "austen_sentiments=[sentence.sentiment.subjectivity for sentence in blob.sentences]\n",
    "np.mean(austen_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=gilman_blob\n",
    "gilman_sentiments=[sentence.sentiment.subjectivity for sentence in blob.sentences]\n",
    "np.mean(gilman_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ▷ Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test of independent values\n",
    "\n",
    "# Inappropriate in this case because zeroes in data make distribution non-normal.\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "print(stats.ttest_ind(melville_sentiments,austen_sentiments))\n",
    "\n",
    "#print stats.ttest_ind(melville_sentiments,gilman_sentiments)\n",
    "\n",
    "#print stats.ttest_ind(austen_sentiments,gilman_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann-Whitney U test\n",
    "\n",
    "# Designed to work for non-normally distrbuted data.\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "print stats.mannwhitneyu(melville_sentiments,austen_sentiments)\n",
    "\n",
    "print stats.mannwhitneyu(melville_sentiments,gilman_sentiments)\n",
    "\n",
    "print stats.mannwhitneyu(austen_sentiments,gilman_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ▷ POS tagging\n",
    "\n",
    "You can find a list of POS tags here: http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'blob_1.tags' is a list of NLTK's best guess for each word's part of speech (POS).\n",
    "# The following prints the first 20 word-tag pairs in our text.\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(blob_1.tags[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print blob_1.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse a sentence's grammar in tree form.\n",
    "\n",
    "blob_1.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ▷ Now let's work with a longer text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Melville's _Moby Dick_\n",
    "\n",
    "import urllib2\n",
    "\n",
    "url=\"http://principalhand.org/workshop-data/Melville_Moby-Dick.txt\"\n",
    "\n",
    "melville_string=urllib2.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TextBlob object and print a random sentence.\n",
    "\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "\n",
    "melville_blob = TextBlob(melville_string)\n",
    "print random.sample(melville_blob.sentences,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the number of times a given word appears in a text.\n",
    "\n",
    "print melville_blob.words.count('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the most frequently occurring words in a text. Note that this is approach is \n",
    "# case-sensitive.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "print Counter(melville_blob.words).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a non-case-sensitive version of the command above, which works by converting the\n",
    "# full text to lowercase before calculating string frequencies.\n",
    "\n",
    "print Counter(melville_blob.words.lower()).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stop Words\n",
    "\n",
    "Now let's view the most frequent words in our corpus with stopwords removed.\n",
    "\n",
    "The first time you run the cell below, uncomment the second line to download all nltk corpora and packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading stop word list\n",
    "\n",
    "from operator import itemgetter\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "stopwords_eng=stopwords.words('english')+[\"'s\"] ## Adding \"'s\"  as a stop word\n",
    "print sorted(stopwords_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new Moby Dick TextBlob object (just for convenience)\n",
    "\n",
    "import urllib2\n",
    "url=\"http://principalhand.org/workshop-data/Melville_Moby-Dick.txt\"\n",
    "melville_string=urllib2.urlopen(url).read()\n",
    "\n",
    "\n",
    "# Create a TextBlob object and print a random sentence.\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "\n",
    "melville_blob = TextBlob(melville_string)\n",
    "print random.sample(melville_blob.sentences,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a copy of our word tally list with stopwords removed.\n",
    "from collections import Counter\n",
    "from textblob import Word\n",
    "from pprint import pprint\n",
    "\n",
    "most_freq=Counter(melville_blob.words.lower()).most_common()\n",
    "\n",
    "most_freq_ns=[]\n",
    "\n",
    "for pair in most_freq:\n",
    "    word=pair[0].lower()\n",
    "    pre_apostrophe=Word(word).split(\"'\"[0]) # \n",
    "    if not (word in stopwords_eng)|(pre_apostrophe in stopwords_eng):\n",
    "        most_freq_ns.append(pair)\n",
    "\n",
    "        \n",
    "print len(most_freq_ns)\n",
    "pprint(most_freq_ns[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that applies the process above to any TextBlob object.\n",
    "\n",
    "def most_freq_no_stop(blob):\n",
    "    stopwords_eng=stopwords.words('english')+[\"'s\"]\n",
    "    most_freq=Counter(blob.words.lower()).most_common()\n",
    "    \n",
    "    most_freq_no_stop=[]\n",
    "\n",
    "    for pair in most_freq:\n",
    "        word=pair[0].lower()\n",
    "        pre_apostrophe=Word(word).split(\"'\"[0])\n",
    "        if not (word in stopwords_eng)|(pre_apostrophe in stopwords_eng):\n",
    "            most_freq_no_stop.append(pair)\n",
    "    \n",
    "    return most_freq_no_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(most_freq_no_stop(melville_blob)[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ▷ Let's load another text for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "url=\"http://principalhand.org/workshop-data/Austen_Persuasion.txt\"\n",
    "\n",
    "austen_string=urllib2.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This cell will throw an error. Don't panic! ####\n",
    "\n",
    "austen_blob = TextBlob(austen_string)\n",
    "pprint(most_freq_no_stop(austen_blob)[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ▷ The cell above will produce a 'UnicodeDecodeError.' To fix the problem, we can apply the \"decode()\" function to our string before passing it to the TextBlob constructor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://principalhand.org/workshop-data/Austen_Persuasion.txt\"\n",
    "\n",
    "austen_string=urllib2.urlopen(url).read().decode(\"utf8\")\n",
    "\n",
    "austen_blob = TextBlob(austen_string)\n",
    "\n",
    "pprint(most_freq_no_stop(austen_blob)[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ▷ Yet another word frequency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "url=\"http://principalhand.org/workshop-data/Gilman_Yellow-Wallpaper.txt\"\n",
    "\n",
    "gilman_string=urllib2.urlopen(url).read().decode(\"utf8\")\n",
    "\n",
    "gilman_blob = TextBlob(gilman_string)\n",
    "\n",
    "pprint(most_freq_no_stop(gilman_blob)[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ▷ Creating a concordance with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import urllib2\n",
    "\n",
    "url=\"http://principalhand.org/workshop-data/Stein_Three-Lives.txt\"\n",
    "temp_string=urllib2.urlopen(url).read().decode('utf8')\n",
    "\n",
    "raw=sanitize(temp_string)\n",
    "\n",
    "\n",
    "nltk_text = nltk.Text([sanitize(temp_string)])\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "nltk_text = nltk.Text(tokens)\n",
    "\n",
    "\n",
    "print nltk_text.concordance('blood')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a rel=\"license\"\n",
    "     href=\"http://creativecommons.org/publicdomain/zero/1.0/\">\n",
    "    <img src=\"http://i.creativecommons.org/p/zero/1.0/88x31.png\" style=\"border-style: none;\" alt=\"CC0\" />\n",
    "  </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
