{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 5: Word-Level Text Analysis\n",
    "\n",
    "\n",
    "Topics to Cover\n",
    "---------------\n",
    "\n",
    "-   comparing word frequency between authors\n",
    "\n",
    "-   part-of-speech (POS) tagging\n",
    "\n",
    "-   POS frequency comparison\n",
    "\n",
    "-   Naive Bayes text classification\n",
    "\n",
    "-   sentiment analysis\n",
    "\n",
    "-   using WordNet\n",
    "\n",
    "\n",
    "### Class Objective\n",
    "Use text analysis techniques introduced by Montfort to examine and compare small text corpora.\n",
    "\n",
    "#### Loading Corpora\n",
    "Today we will be analyzing and comparing two small text corpora. Choose two text sets from the following list:\n",
    "\n",
    "- [Works of Ralph Waldo Emerson](http://www.stephenmclaughlin.net/pcda/sample-data/week-4/Emerson.zip)\n",
    "- [Works of Oscar Wilde](http://www.stephenmclaughlin.net/pcda/sample-data/week-4/Wilde.zip)\n",
    "\n",
    "Open Terminal in macOS and launch our Docker container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import textblob\n",
    "from operator import itemgetter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download zipped texts from GitHub, then unzip the directory.\n",
    "\n",
    "import os\n",
    "os.chdir('/sharedfolder/')\n",
    "\n",
    "!wget -y https://github.com/pcda17/pcda17.github.io/blob/master/week/5/Emerson.zip?raw=true -O Emerson.zip\n",
    "!unzip Emerson.zip\n",
    "\n",
    "!wget -y https://github.com/pcda17/pcda17.github.io/blob/master/week/5/Wilde.zip?raw=true -O Wilde.zip\n",
    "!unzip Wilde.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load each author's text files as a list of strings.\n",
    "\n",
    "corpus1_dir = \"/sharedfolder/Emerson/\"\n",
    "corpus2_dir = \"/sharedfolder/Wilde/\"\n",
    "\n",
    "##\n",
    "\n",
    "os.chdir(corpus1_dir)\n",
    "\n",
    "corpus1_filenames = os.listdir(\"./\")\n",
    "\n",
    "corpus1_texts=[]\n",
    "\n",
    "for filename in corpus1_filenames:\n",
    "    text = open(filename).read().replace(\"\\n\",\" \") #replaces newlines with spaces\n",
    "    corpus1_texts.append(text)\n",
    "\n",
    "##\n",
    "    \n",
    "os.chdir(corpus2_dir)\n",
    "\n",
    "corpus2_filenames = os.listdir(\"./\")\n",
    "\n",
    "corpus2_texts=[]\n",
    "\n",
    "for filename in corpus2_filenames:\n",
    "    text = open(filename).read().replace(\"\\n\",\" \") #replaces newline characters with spaces\n",
    "    corpus2_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts:\n",
      "17\n",
      "\n",
      "Random text head: \n",
      "\n",
      "                                      1890                                    CHARMIDES                                  by Oscar Wilde                         I      He was a Grecian lad, who coming home       With pulpy figs and wine from Sicily     Stood at his galley's prow, and let the foam       Blow through his crisp brown curls unconsciously,     And holding wind and wave in boy's despite     Peered from his dripping seat across the wet and         stormy night.      Till with the dawn he saw a burnished spear       Like a thin thread of gold against the sky,     And hoisted sail, and strained the creeking gear,       And bade the pilot head her lustily     Against the nor-west gale, and all day long     Held on his way, and marked the rowers' time with         measured song.      And when the faint Corinthian hills were red       Dropped anchor in a little sandy bay,     And with fresh boughs of olive crowned his head,       And brushed from cheek and throat the hoary spray,     And washed his limbs with oil, and from the hold     Brought out his linen tunic and his sandals         brazen-soled.      And a rich robe stained with the fishes' juice       Which of some swarthy trader he had bought     Upon the sunny quay at Syracuse,       And was with Tyrian broideries inwrought,     And by the questioning merchants made his way     Up through the soft and silver woods, and when the         laboring day      Had spun its tangled web of crimson cloud,       Clomb the high hill, and with swift silent feet     Crept to the fane unnoticed by the crowd       Of busy priests, and from some dark retreat     Watched the young swains his frolic playmates bring     The firstling of their little flock, and the shy         shepherd fling      The crackling salt upon the flame, or hang       His studded crook against the temple wall     To Her who keeps away the ravenous fang       Of the base wolf from homestead and from stall;     And then the clear-voiced maidens 'gan to sing,     And to the altar each man brought some goodly         offering,      A beechen cup brimming with milky foam,       A fair cloth wrought with cunning imagery     Of hounds in chase, a waxen honeycomb       Dripping with oozy gold which scarce the bee     Had ceased from building, a black skin of oil     Meet for the wrestlers, a great boar the fierce          and white-tusked spoil      Stolen from Artemis that jealous maid       To please Athena, and the dappled hide     Of a tall stag who in some mountain glade       Had met the shaft; and then the herald cried,     And from the pillared precinct one by one     Went the glad Greeks well pleased that they their         simple vows had done.      And the old priest put out the waning fires       Save that one lamp whose restless ruby glowed     For ever in the cell, and the shrill lyres       Came fainter on the wind, as down the road     In joyous dance these country folk did pass,     And with stout hands the warder closed the gates         of polished brass.      Long time he lay and hardly dared to breathe,       And heard the cadenced drip of spilt-out wine,     And the rose-petals falling from the wreath       As the night breezes wandered through the shrine,     And seemed to be in some entranced swoon     Till through the open roof above the full and         brimming moon      Flooded with sheeny waves the marble floor,       When from his nook upleapt the venturous lad,     And flinging wide the cedar-carven door       Beheld an awful image saffron-clad     And armed for battle! the gaunt Griffin glared     From the huge helm, and the long lance of wreck and         ruin flared      Like a red rod of flame, stony and steeled       The Gorgon's head its leaden eyeballs rolled,     And writhed its snaky horrors through the shield,       And gaped aghast with bloodless lips and cold     In passion impotent, while with blind gaze     The blinking owl between the feet hooted in shrill         amaze. \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "print('Number of texts:')\n",
    "print(len(corpus2_texts))\n",
    "\n",
    "print()\n",
    "\n",
    "random_filename = random.choice(corpus2_texts)\n",
    "print('Random text head: \\n\\n' + random_filename[:4000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *> TextBlob Review*\n",
    "\n",
    "Let’s review the TextBlob package, introduced in this week’s reading by Nick Montfort. First, let’s load TextBlob and convert two texts to lists of words. \n",
    "\n",
    "Note that each is contained in a WordList object, which we can manipulate as if it were an ordinary list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AN', 'ADDRESS', 'Delivered', 'before', 'the', 'Senior', 'Class', 'in', 'Divinity', 'College', 'Cambridge', 'Sunday', 'Evening', 'July', '15']\n",
      "\n",
      "['1898', 'THE', 'BALLAD', 'OF', 'READING', 'GAOL', 'by', 'Oscar', 'Wilde', 'I', 'He', 'did', 'not', 'wear', 'his']\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text1=TextBlob(corpus1_texts[0])\n",
    "print(text1.words[:15])\n",
    "\n",
    "print()\n",
    "\n",
    "text2=TextBlob(corpus2_texts[0])\n",
    "print(text2.words[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"        AN ADDRESS           _Delivered before the Senior Class in Divinity College, Cambridge, Sunday Evening, July 15, 1838_             In this refulgent summer, it has been a luxury to draw the breath of life.\"), Sentence(\"The grassurst, the meadow is spotted with fire and gold in the tint of flowers.\"), Sentence(\"The air is full of birds, and sweet with the breath of the pine, the balm-of-Gilead, and the new hay.\"), Sentence(\"Night brings no gloom to the heart with its welcome shade.\"), Sentence(\"Through the transparent darkness the stars pour their almost spiritual rays.\")]\n",
      "\n",
      "[Sentence(\"                                      1898                            THE BALLAD OF READING GAOL                                  by Oscar Wilde                         I          He did not wear his scarlet coat,           For blood and wine are red,         And blood and wine were on his hands           When they found him with the dead,         The poor dead woman whom he loved,           And murdered in her bed.\"), Sentence(\"He walked amongst the Trial Men           In a suit of shabby gray;         A cricket cap was on his head,           And his step seemed light and gay;         But I never saw a man who looked           So wistfully at the day.\"), Sentence(\"I never saw a man who looked           With such a wistful eye         Upon that little tent of blue           Which prisoners call the sky,         And at every drifting cloud that went           With sails of silver by.\"), Sentence(\"I walked, with other souls in pain,           Within another ring,         And was wondering if the man had done           A great or little thing,         When a voice behind me whispered low,           \"That fellow's got to swing.\"\"), Sentence(\"Dear Christ!\")]\n"
     ]
    }
   ],
   "source": [
    "print(text1.sentences[:5])\n",
    "print()\n",
    "print(text2.sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", '1', '15', '1838', '2', 'A', 'A', 'A', 'A', 'A', 'A', 'ADDRESS', 'AN', 'Accept', 'Ah', 'Alas', 'All', 'All', 'All', 'All', 'All', 'All', 'Alone', 'Already', 'Always', 'America', 'America', 'And', 'And', 'And', 'And', 'And', 'And', 'And', 'And', 'And', 'And', 'And', 'And', 'Apollo', 'As', 'As', 'As', 'As', 'Be', 'Beauty', 'Beauty', 'Beauty', 'Behold', 'Behold', 'Benevolence', 'Bible', 'Boldly', 'But', 'But', 'But', 'But', 'But', 'But', 'But', 'But', 'But', 'But', 'But', 'But', 'But', 'But', 'By', 'By', 'By', 'Cambridge', 'Can', 'Catholic', 'Certainly', 'Character', 'China', 'Christ', 'Christ', 'Christ', 'Christ', 'Christ', 'Christ', 'Christ', 'Christ', 'Christ', 'Christ', 'Christian', 'Christian', 'Christian', 'Christian', 'Christian', 'Christianity', 'Christianity', 'Christianity', 'Christianity', 'Christianity', 'Christianity', 'Christianity', 'Church', 'Church', 'Church', 'Church', 'Class', 'College', 'Courage', 'Cultus', 'Cultus', 'Deity', 'Delivered', 'Denderah', 'Discharge', 'Divinity', 'Drawn', 'Duty', 'East', 'Egypt', 'Egypt', 'England', 'Epaminondas', 'Europe', 'Europe', 'Evening', 'Every', 'Everything', 'Evil', 'Faith', 'For', 'For', 'For', 'Fox', 'French', 'Friends', 'From', 'Genius', 'George', 'Ghost', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'God', 'Good', 'Greece', 'Greek', 'Greeks', 'Guard', 'Having', 'He', 'He', 'He', 'He', 'He', 'He', 'He', 'He', 'He', 'He', 'He', 'He', 'He', 'He', 'He', 'He', 'He', 'He', 'Hebrew', 'Hebrews', 'Hindoos', 'Historical', 'Holy', 'How', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'If', 'If', 'If', 'If', 'If', 'Imitation', 'Imperial', 'In', 'In', 'In', 'In', 'In', 'In', 'In', 'In', 'In', 'In', 'In', 'In', 'In', 'In', 'India', 'Instantly', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'It', 'Its', 'Jehovah', 'Jesus', 'Jesus', 'Jesus', 'Jesus', 'Jesus', 'Jesus', 'Joy', 'July', 'Law', 'Law', 'Law', 'Law', 'Law', 'Law', 'Law', 'Let', 'Let', 'Let', 'Let', 'Let', 'Let', 'Let', 'Life', 'Literature', 'Look', 'Lord', 'Man', 'Man', 'Man', 'Massena', 'Meantime', 'Men', 'Men', 'Miracle', 'Miracles', 'Monster', 'Moral', 'Moreover', 'Moses', 'Moses', 'My', 'Mythus', 'Napoleon', 'Nature', 'Night', 'Noble', 'None', 'None', 'Not', 'Not', 'Not', 'Not', 'Now', 'Now', 'O', 'Oberlins', 'Obey', 'Of', 'On', 'On', 'On', 'Once', 'Once', 'One', 'One', 'One', 'One', 'Orientals', 'Osiris', 'Ought', 'Palestine', 'Paul', 'Persia', 'Preaching', 'Prophets', 'Providence', 'Puritans', 'Rather', 'Reason', 'Reason', 'Reason', 'Right', 'Rome', 'Sabbath', 'Sabbath', 'Sabbath', 'Sabbath', 'Saints', 'Science', 'Science', 'Scriptures', 'See', 'See', 'See', 'Self', 'Senior', 'Slight', 'So', 'So', 'So', 'Society', 'Society', 'Somehow', 'Soul', 'Soul', 'Speak', 'Spirit', 'Spirit', 'St', 'Such', 'Sunday', 'Sundays', 'Supper', 'Supreme', 'Supreme', 'Swedenborg', 'Teacher', 'Thank', 'That', 'That', 'That', 'That', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'Thefts', 'Then', 'Then', 'Then', 'Then', 'There', 'There', 'There', 'There', 'There', 'There', 'These', 'These', 'These', 'These']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(text1.words)[:500])  # prints first 500 words in alphabetized word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", '1', '15', '1838', '2', 'A', 'ADDRESS', 'AN', 'Accept', 'Ah', 'Alas', 'All', 'Alone', 'Already', 'Always', 'America', 'And', 'Apollo', 'As', 'Be', 'Beauty', 'Behold', 'Benevolence', 'Bible', 'Boldly', 'But', 'By', 'Cambridge', 'Can', 'Catholic', 'Certainly', 'Character', 'China', 'Christ', 'Christian', 'Christianity', 'Church', 'Class', 'College', 'Courage', 'Cultus', 'Deity', 'Delivered', 'Denderah', 'Discharge', 'Divinity', 'Drawn', 'Duty', 'East', 'Egypt', 'England', 'Epaminondas', 'Europe', 'Evening', 'Every', 'Everything', 'Evil', 'Faith', 'For', 'Fox', 'French', 'Friends', 'From', 'Genius', 'George', 'Ghost', 'God', 'Good', 'Greece', 'Greek', 'Greeks', 'Guard', 'Having', 'He', 'Hebrew', 'Hebrews', 'Hindoos', 'Historical', 'Holy', 'How', 'I', 'If', 'Imitation', 'Imperial', 'In', 'India', 'Instantly', 'It', 'Its', 'Jehovah', 'Jesus', 'Joy', 'July', 'Law', 'Let', 'Life', 'Literature', 'Look', 'Lord', 'Man', 'Massena', 'Meantime', 'Men', 'Miracle', 'Miracles', 'Monster', 'Moral', 'Moreover', 'Moses', 'My', 'Mythus', 'Napoleon', 'Nature', 'Night', 'Noble', 'None', 'Not', 'Now', 'O', 'Oberlins', 'Obey', 'Of', 'On', 'Once', 'One', 'Orientals', 'Osiris', 'Ought', 'Palestine', 'Paul', 'Persia', 'Preaching', 'Prophets', 'Providence', 'Puritans', 'Rather', 'Reason', 'Right', 'Rome', 'Sabbath', 'Saints', 'Science', 'Scriptures', 'See', 'Self', 'Senior', 'Slight', 'So', 'Society', 'Somehow', 'Soul', 'Speak', 'Spirit', 'St', 'Such', 'Sunday', 'Sundays', 'Supper', 'Supreme', 'Swedenborg', 'Teacher', 'Thank', 'That', 'The', 'Thefts', 'Then', 'There', 'These', 'They', 'This', 'Thought', 'Through', 'Thus', 'To', 'Truly', 'Truth', 'Two', 'Understanding', 'Virtue', 'Washington', 'We', 'Wesleys', 'West', 'What', 'When', 'Whenever', 'Where', 'Wherever', 'Whilst', 'Will', 'Wisdom', 'Wonderful', 'Would', 'Yet', 'You', 'Yourself', 'Zeno', 'Zoroaster', 'a', 'ability', 'about', 'above', 'absence', 'absent', 'absolute', 'abundant', 'accept', 'accepted', 'accepting', 'accepts', 'account', 'accuses', 'aches', 'acquaint', 'acquaintance', 'across', 'act', 'acted', 'action', 'actions', 'active', 'activity', 'actors', 'acts', 'addresses', 'adequately', 'administration', 'admiration', 'admire', 'admixture', 'admonish', 'adores', 'advance', 'advantages', 'affect', 'affection', 'affections', 'affinity', 'affirms', 'afford', 'after', 'afternoon', 'again', 'against', 'age', 'ages', 'ago', 'agreeable', 'aim', 'aims', 'air', 'aisles', 'alike', 'alive', 'all', 'all-knowing', 'allied', 'allowance', 'almost', 'alms', 'alone', 'already', 'also', 'altar', 'always', 'am', 'ambition', 'amid', 'amidst', 'among', 'an', 'analysis', 'ancient', 'and', 'anew', 'angel', 'angels', 'animals', 'annihilates', 'announces', 'another', 'answered', 'anthems', 'anxious', 'any', 'anything', 'appeal', 'appear', 'appearance', 'appearances', 'appeared', 'appears', 'appendage', 'appetite', 'applause', 'application', 'applications', 'applies', 'appreciated', 'apprehension', 'appropriated', 'are', 'arises', 'around', 'art', 'articulated', 'artist', 'as', 'ascends', 'ashamed', 'ask', 'asks', 'aspiration', 'aspirations', 'assayeth', 'associate', 'assumption', 'assurance', 'astonish', 'astonishment', 'astronomers', 'astronomical', 'at', 'atmosphere', 'attains', 'attempt', 'attempts', 'attend', 'attraction', 'attributed', 'attributes', 'august', 'austere', 'authority', 'auxiliaries', 'avoiding', 'awakens', 'away', 'awe', 'awoke', 'babbles', 'bad', 'badness', 'baffled', 'balked', 'balm-of-Gilead', 'bandages', 'bard', 'bards', 'base', 'bathes', 'battle', 'baubles', 'be', 'bear', 'beatitude', 'beautiful', 'beauty', 'became', 'because', 'become', 'becomes', 'been', 'befalls', 'befel', 'before', 'began', 'beget', 'begin', 'beginning', 'behind', 'behooted', 'behowled', 'being', 'belief', 'believe', 'believeth', 'belonged', 'beloved', 'benefit', 'benevolence', 'bereaved', 'bereaves', 'best', 'better', 'biography', 'bird', 'birds', 'birth', 'bitterness', 'blasphemer', 'blend', 'bless', 'blessed', 'blessings', 'blind', 'blowing', 'bold', 'books', 'born', 'bought', 'bound', 'bounty', 'brave', 'bread', 'breadth', 'break', 'breath', 'breathed', 'bride', 'bring', 'bringing', 'brings', 'broad', 'broke', 'brothers', 'brute', 'builded', 'builders', 'built', 'burden', 'business', 'but', 'by', 'by-ends', 'calamity', 'call', 'called', 'can', 'canvas', 'capital', 'captains', 'cast', 'catachetical', 'caught', 'causes', 'cease', 'cells', 'centuries', 'certain', 'certainly', 'chagrined', 'channels', 'chant', 'character', 'characterizes', 'charm', 'chasm', 'cheaply', 'cheated', 'check', 'cheer', 'cheerful', 'chemical', 'chide', 'chiefly', 'child', 'chisel', 'chlorine', 'chooses', 'church', 'churches', 'circle', 'circumstance', 'cities', 'citizen', 'civil', 'civilized', 'claims', 'clamor', 'classes', 'clatter', 'clearest', 'clearness', 'clergy', 'cloaks', 'closed', 'closet', 'cloud', 'clover', 'coeval', 'cold', 'combination', 'come', 'comes', 'comforts', 'comic', 'coming', 'command', 'commanded', 'commanders', 'commanding', 'commands', 'commendation', 'commended', 'commending', 'commission', 'common', 'common-places', 'communicate']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(list(set(text1.words)))[:500]) # prints sorted list of unique words (first 500 items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each TextBlob object contains a dictionary with the number of times each word appears in a text.\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(text1.word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *> Quick Exercise*\n",
    "\n",
    "Create a function that returns the top 20 most frequent words in a given TextBlob object. \n",
    "\n",
    "\n",
    "*Hint: Use the `itemgetter` module to sort a list of lists by a given index.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 561],\n",
      " ['of', 339],\n",
      " ['and', 320],\n",
      " ['to', 196],\n",
      " ['is', 170],\n",
      " ['in', 165],\n",
      " ['a', 124],\n",
      " ['that', 123],\n",
      " ['it', 98],\n",
      " ['not', 87],\n",
      " ['he', 83],\n",
      " ['man', 63],\n",
      " ['as', 61],\n",
      " ['all', 59],\n",
      " ['with', 53],\n",
      " ['this', 52],\n",
      " ['his', 51],\n",
      " ['be', 50],\n",
      " ['by', 46],\n",
      " ['but', 46],\n",
      " ['or', 45],\n",
      " ['are', 44],\n",
      " ['i', 44],\n",
      " ['you', 44],\n",
      " ['soul', 41],\n",
      " ['which', 40],\n",
      " ['can', 39],\n",
      " ['we', 37],\n",
      " ['they', 37],\n",
      " ['for', 34]]\n"
     ]
    }
   ],
   "source": [
    "# A possible solution:\n",
    "\n",
    "from operator import itemgetter\n",
    "from pprint import pprint\n",
    "\n",
    "freq_dict=text1.word_counts\n",
    "freq_list=[]\n",
    "\n",
    "for key in freq_dict:\n",
    "    freq_list.append([key,freq_dict[key]])\n",
    "\n",
    "sorted_freq_list=sorted(freq_list, key=itemgetter(1))[::-1]\n",
    "\n",
    "pprint(sorted_freq_list[:30])\n",
    "\n",
    "# What do you notice about these words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *> Word Frequency Sans Stopwords*\n",
    "\n",
    "Next we'll load the `nltk` module, which was installed as a dependency of TextBlob.\n",
    "\n",
    "In computational text analysis, the term “stopword” refers to words that appear\n",
    "frequently in most texts in a given language — e.g., “I,” “the,” “and,” “while,”\n",
    "and so on. NLTK provides a useful stopword list. Here we assign the English stopword \n",
    "list to the variable `stopwords_eng`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_eng = stopwords.words('english')\n",
    "\n",
    "print(stopwords_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['man', 63],\n",
      " ['soul', 41],\n",
      " ['men', 32],\n",
      " ['god', 27],\n",
      " ['life', 26],\n",
      " ['shall', 25],\n",
      " ['one', 22],\n",
      " ['us', 22],\n",
      " ['good', 21],\n",
      " ['love', 20],\n",
      " ['was', 20],\n",
      " ['world', 20],\n",
      " ['see', 19],\n",
      " ['has', 18],\n",
      " ['sentiment', 17],\n",
      " ['heart', 17],\n",
      " ['let', 16],\n",
      " ['true', 15],\n",
      " ['nature', 15],\n",
      " ['would', 15]]\n"
     ]
    }
   ],
   "source": [
    "# Now let’s look at the most frequent words in a text, disregarding stopwords.\n",
    "\n",
    "from textblob import Word\n",
    "\n",
    "freq_dict = text1.word_counts\n",
    "\n",
    "freq_sans_stopwords = []\n",
    "\n",
    "for key in freq_dict:\n",
    "    lemma = Word(key).lemmatize()\n",
    "    if lemma not in stopwords_eng:\n",
    "        freq_sans_stopwords.append([key,freq_dict[key]])\n",
    "\n",
    "sorted_freq_sans_stopwords = sorted(freq_sans_stopwords, key = itemgetter(1))[::-1]\n",
    "\n",
    "pprint(sorted_freq_sans_stopwords[:20])\\\n",
    "\n",
    "# How do you interpret this list? Does it give you any insight into the text you’re looking at?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## *> Quick Exercise*\n",
    "\n",
    "Referencing the code above, create a function that returns a sorted list of stopword-free word frequency lists when passed a TextBlob object. Look at the top vocabulary for several texts by each of your authors. How similar or different are these frequency lists between texts and between authors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['man', 63],\n",
      " ['soul', 41],\n",
      " ['men', 32],\n",
      " ['god', 27],\n",
      " ['life', 26],\n",
      " ['shall', 25],\n",
      " ['one', 22],\n",
      " ['us', 22],\n",
      " ['good', 21],\n",
      " ['love', 20],\n",
      " ['was', 20],\n",
      " ['world', 20],\n",
      " ['see', 19],\n",
      " ['has', 18],\n",
      " ['sentiment', 17],\n",
      " ['heart', 17],\n",
      " ['let', 16],\n",
      " ['true', 15],\n",
      " ['nature', 15],\n",
      " ['would', 15]]\n",
      "\n",
      "[['man', 38],\n",
      " ['was', 30],\n",
      " ['men', 22],\n",
      " ['day', 21],\n",
      " ['upon', 18],\n",
      " ['like', 17],\n",
      " ['little', 14],\n",
      " ['one', 14],\n",
      " ['does', 13],\n",
      " ['thing', 13],\n",
      " ['heart', 13],\n",
      " ['soul', 12],\n",
      " ['never', 12],\n",
      " ['dead', 11],\n",
      " ['night', 11],\n",
      " ['red', 10],\n",
      " ['saw', 10],\n",
      " ['every', 10],\n",
      " ['round', 10],\n",
      " ['us', 10]]\n"
     ]
    }
   ],
   "source": [
    "# A possible solution:\n",
    "\n",
    "def topwords(blob):\n",
    "    stopwords_eng = stopwords.words('english')\n",
    "    freq_dict=blob.word_counts\n",
    "    freq_sans_stopwords = []\n",
    "    for key in freq_dict:\n",
    "        lemma = Word(key).lemmatize()\n",
    "        if lemma not in stopwords_eng:\n",
    "            freq_sans_stopwords.append([key, freq_dict[key]])\n",
    "    sorted_freq_sans_stopwords=sorted(freq_sans_stopwords, key=itemgetter(1))[::-1]\n",
    "    return sorted_freq_sans_stopwords\n",
    "\n",
    "pprint(topwords(text1)[:20])\n",
    "print()\n",
    "pprint(topwords(text2)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging\n",
    "\n",
    "We can also use TextBlob to create a list of part-of-speech tags for each word in a text.\n",
    "\n",
    "Let’s take a close look at our results. Examine two or three sentences a word at a time and check whether parts of speech were tagged correctly. If you find any mistakes, can you guess why the tagging algorithm slipped up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(text1.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n"
     ]
    }
   ],
   "source": [
    "# Following Montfort’s example, let’s create a function that counts the number of adjectives in a text.\n",
    "\n",
    "def adjs(text):\n",
    "    count = 0\n",
    "    for word, tag in text.tags:\n",
    "        if tag == 'JJ':\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "print(adjs(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06812321888994437\n"
     ]
    }
   ],
   "source": [
    "def adj_percent(text):\n",
    "    return float(adjs(text))/len(text.words)\n",
    "\n",
    "print(adj_percent(text1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## *> Exercise*\n",
    "\n",
    "Create a function called `POS_profile` that takes a TextBlob object and returns a list containing several parts of speech and their relative frequency within the text. Your POS profile should include the following parts of speech:\n",
    "\n",
    "- nouns\n",
    "- adjectives\n",
    "- verbs\n",
    "- adverbs\n",
    "- pronouns\n",
    "\n",
    "You can find a full list of POS tags used by TextBlob [here](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html). Note that several parts of speech are split into multiple codes (e.g., NN, NNS, NNP, and NNPS for different classes of noun).\n",
    "\n",
    "Next, run your POS profile on each text in your two corpora. How much do these values vary between authors and among texts by the same author?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A possible solution:\n",
    "\n",
    "def POS_profile(blob):\n",
    "    noun_codes=['NN','NNS','NNP','NNPS']\n",
    "    adj_codes=['JJ','JJR','JJS']\n",
    "    verb_codes=['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "    adv_codes=['RB','RBR','RBS']\n",
    "    pronoun_codes=['PRP']\n",
    "    noun_count=0\n",
    "    adj_count=0\n",
    "    verb_count=0\n",
    "    adv_count=0\n",
    "    pronoun_count=0\n",
    "    for (word, tag) in blob.tags:\n",
    "        if tag in noun_codes: noun_count+=1\n",
    "        if tag in adj_codes: adj_count+=1\n",
    "        if tag in verb_codes: verb_count+=1\n",
    "        if tag in adv_codes: adv_count+=1\n",
    "        if tag in pronoun_codes: pronoun_count+=1\n",
    "    word_count=len(blob.words)\n",
    "    return [float(noun_count)/word_count, float(adj_count)/word_count, float(verb_count)/word_count, float(adv_count)/word_count, float(pronoun_count)/word_count]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Naive Bayes Classification\n",
    "\n",
    "Review classification examples from Montfort text.\n",
    "\n",
    "## *> Exercise*\n",
    "\n",
    "Divide each of your corpora into two sets, one for training our classifier and one for testing. Split each text into a list of sentences and combine these to create four master lists: author 1 training, author 1 testing, author 2 training, author 2 testing.\n",
    "\n",
    "Create a Naive Bayes classifier using your two training sets. Run the classifier on each sentence in your test sets and calculate the accuracy of your model.\n",
    "\n",
    "Examine sentences that were misclassified. Why do you think the algorithm was misled?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *> Sentiment Analysis*\n",
    "\n",
    "If time permits.\n",
    "\n",
    "## *> Using WordNet*\n",
    "\n",
    "If time permits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
